{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:05:53.317811Z",
     "iopub.status.busy": "2024-11-15T23:05:53.317673Z",
     "iopub.status.idle": "2024-11-15T23:05:55.130839Z",
     "shell.execute_reply": "2024-11-15T23:05:55.130068Z"
    },
    "id": "c-y6aHFHsGkL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "#grab data from working directory\n",
    "main_data = pd.read_csv('data/data.csv')\n",
    "training_data = pd.read_csv('data/training_data.csv')\n",
    "validation_data = pd.read_csv('data/validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T23:05:55.133623Z",
     "iopub.status.busy": "2024-11-15T23:05:55.133375Z",
     "iopub.status.idle": "2024-11-15T23:05:55.232155Z",
     "shell.execute_reply": "2024-11-15T23:05:55.231328Z"
    },
    "id": "TN9AsqrMTuj8",
    "outputId": "fb96383d-f932-41fb-9a60-8ae52dd27562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "ltype = torch.long\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:05:55.285936Z",
     "iopub.status.busy": "2024-11-15T23:05:55.285578Z",
     "iopub.status.idle": "2024-11-15T23:05:58.176757Z",
     "shell.execute_reply": "2024-11-15T23:05:58.176037Z"
    },
    "id": "_m12BBOqyqfa"
   },
   "outputs": [],
   "source": [
    "# prompt: write 2 data preprocessing functions\n",
    "# the first one filters out all rows that have an empty 'problem_tags' column or have the problem_tags column include \"*specialproblem\". it also filters out all rows that have empty problem_statement columns\n",
    "# the second function will split the problem_tags column and split it into two columns. the first resulting column will just be the original problem_tags column and the second resulting column will be rating.\n",
    "# the problem tags column is originally a comma seperated list and should include some value that looks like *2400 or *2300 or *900, these values are ratings. there should be only one of them, take the rating value and put it in the rating column. if there is a problem with no rating value in its 'problem_tags' column it should be filtered out\n",
    "\n",
    "def preprocess_data_1(df):\n",
    "  \"\"\"\n",
    "  Filters out rows with empty 'problem_tags' or 'problem_statement' columns,\n",
    "  and rows where 'problem_tags' contains '*specialproblem'.\n",
    "  \"\"\"\n",
    "  df = df.dropna(subset=['problem_tags', 'problem_statement'])\n",
    "  df = df[~df['problem_tags'].str.contains(r\"\\*specialproblem\", na=False)]\n",
    "  return df\n",
    "\n",
    "def preprocess_data_2(df):\n",
    "  \"\"\"\n",
    "  Splits the 'problem_tags' column into two columns: 'problem_tags' (original)\n",
    "  and 'rating'. Extracts the rating value from the 'problem_tags' column if\n",
    "  it exists, otherwise filters out the row.\n",
    "  \"\"\"\n",
    "  def extract_rating(tags):\n",
    "    if isinstance(tags, str):\n",
    "      for tag in tags.split(','):\n",
    "        if '*' in tag and tag.replace('*', '').isdigit():\n",
    "          return int(tag.replace('*', ''))\n",
    "    return None\n",
    "\n",
    "  df.loc[:, 'rating'] = df['problem_tags'].apply(extract_rating)\n",
    "\n",
    "  #drop rows with no rating\n",
    "  df = df.dropna(subset=['rating'])\n",
    "\n",
    "  for i in range(len(df)):\n",
    "    good_tags = []\n",
    "    for tag in df.iloc[i]['problem_tags'].split(','):\n",
    "      if '*' not in tag and tag.split():\n",
    "        good_tags.append(tag)\n",
    "    df.loc[df.index[i], 'problem_tags'] = ','.join(good_tags)\n",
    "\n",
    "  #drop problems with empty string for tags\n",
    "  df = df[df['problem_tags'] != '']\n",
    "\n",
    "  return df\n",
    "\n",
    "main_data = preprocess_data_1(main_data)\n",
    "main_data = preprocess_data_2(main_data)\n",
    "training_data = preprocess_data_1(training_data)\n",
    "training_data = preprocess_data_2(training_data)\n",
    "validation_data = preprocess_data_1(validation_data)\n",
    "validation_data = preprocess_data_2(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9xqRg25sVKR"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T23:05:58.179712Z",
     "iopub.status.busy": "2024-11-15T23:05:58.179552Z",
     "iopub.status.idle": "2024-11-15T23:05:58.187491Z",
     "shell.execute_reply": "2024-11-15T23:05:58.187031Z"
    },
    "id": "2D-sNGFsunvb",
    "outputId": "05cff6e7-f06e-466d-e10a-11f51767a1e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most frequent tags are: {'implementation', 'datastructures', 'constructivealgorithms', 'bruteforce', 'graphs', 'math', 'greedy', 'sortings', 'dp', 'binarysearch'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = 10  # Hyperparameter for the number of most frequent tags\n",
    "\n",
    "all_tags = []\n",
    "for tags in main_data['problem_tags'].dropna():\n",
    "    all_tags.extend(tags.split(','))\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "tag_counts = Counter(all_tags)\n",
    "most_frequent_tags = set([tag for tag, count in tag_counts.most_common(n)])\n",
    "index_to_tag = {i: tag for i, tag in enumerate(most_frequent_tags)}\n",
    "tag_to_index = {tag: i for i, tag in index_to_tag.items()}\n",
    "print(f\"The {n} most frequent tags are: {most_frequent_tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T23:05:58.189491Z",
     "iopub.status.busy": "2024-11-15T23:05:58.189348Z",
     "iopub.status.idle": "2024-11-15T23:05:58.196316Z",
     "shell.execute_reply": "2024-11-15T23:05:58.195858Z"
    },
    "id": "9zzxX6lq1mJa",
    "outputId": "9eb6af6e-f327-4dd0-e2b0-2818c17f5413"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of problems with at least one of the top 10 tags: 94.80%\n"
     ]
    }
   ],
   "source": [
    "# prompt: what percent of problems use a tag found in the n most common ?\n",
    "\n",
    "problems_with_top_n_tags = 0\n",
    "total_problems = len(main_data)\n",
    "\n",
    "for tags in main_data['problem_tags'].dropna():\n",
    "  if isinstance(tags, str):\n",
    "    for tag in tags.split(','):\n",
    "      if tag in most_frequent_tags:\n",
    "        problems_with_top_n_tags += 1\n",
    "        break  # Only count the problem once if it has at least one top-n tag\n",
    "\n",
    "percentage = (problems_with_top_n_tags / total_problems) * 100\n",
    "print(f\"Percentage of problems with at least one of the top {n} tags: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T23:05:58.198535Z",
     "iopub.status.busy": "2024-11-15T23:05:58.198307Z",
     "iopub.status.idle": "2024-11-15T23:05:58.907668Z",
     "shell.execute_reply": "2024-11-15T23:05:58.907048Z"
    },
    "id": "t3S0Gg_I5hWH",
    "outputId": "9f9c25d4-babe-480f-98f7-a9478eff4f2c"
   },
   "outputs": [],
   "source": [
    "# prompt: make a histogram for the ratings a bar graph for the frequency of each tag in the top n\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming 'main_data' and 'most_frequent_tags' are defined as in your previous code\n",
    "\n",
    "# Histogram for ratings\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(training_data['rating'], bins=10, edgecolor='black')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Problem Ratings')\n",
    "plt.show()\n",
    "\n",
    "print(len(training_data))\n",
    "\n",
    "# Bar graph for tag frequency\n",
    "tag_frequencies = Counter([tag for tags in training_data['problem_tags'].dropna() for tag in tags.split(',') if tag in most_frequent_tags])\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(tag_frequencies.keys(), tag_frequencies.values())\n",
    "plt.xlabel('Tags')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Frequency of Top {n} Tags')\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#bar graph for how many problems have k different tags in the top n\n",
    "tag_counts = {}\n",
    "for tags in training_data['problem_tags'].dropna():\n",
    "  if isinstance(tags, str):\n",
    "    tag_count = len(tags.split(','))\n",
    "    if tag_count in tag_counts:\n",
    "      tag_counts[tag_count] += 1\n",
    "    else:\n",
    "      tag_counts[tag_count] = 1\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(tag_counts.keys(), tag_counts.values())\n",
    "plt.xlabel('Number of Tags')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Frequency of Number of Tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T23:05:58.910151Z",
     "iopub.status.busy": "2024-11-15T23:05:58.909556Z",
     "iopub.status.idle": "2024-11-15T23:06:00.724040Z",
     "shell.execute_reply": "2024-11-15T23:06:00.723311Z"
    },
    "id": "6jDVLvpW5wX0",
    "outputId": "379ecb66-1ba1-4c9f-8d11-29d585db79d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28118\n"
     ]
    }
   ],
   "source": [
    "# prompt: write a transformation of the training data set where for each problem. lets say the problem has k tags, we include 2^k total versions of the problem, each with all the subsets of its tags, afterwords print the length of the training dataset\n",
    "\n",
    "def transform_training_data(df):\n",
    "    transformed_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        tags = row['problem_tags'].split(',')\n",
    "        tags = [tag for tag in tags if tag in most_frequent_tags]\n",
    "        num_tags = len(tags)\n",
    "        for i in range(2**num_tags):\n",
    "            subset_tags = []\n",
    "            for j in range(num_tags):\n",
    "                if (i >> j) & 1:\n",
    "                    subset_tags.append(tags[j])\n",
    "            new_row = row.copy()\n",
    "            new_row['problem_tags'] = ','.join(subset_tags)\n",
    "            transformed_data.append(new_row)\n",
    "    return pd.DataFrame(transformed_data)\n",
    "\n",
    "training_data = transform_training_data(training_data)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:06:00.725972Z",
     "iopub.status.busy": "2024-11-15T23:06:00.725800Z",
     "iopub.status.idle": "2024-11-15T23:06:01.183493Z",
     "shell.execute_reply": "2024-11-15T23:06:01.182542Z"
    },
    "id": "f9f6RWvW92zv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/nt406/Desktop/cf-classification/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# prompt: now make a function that takes  the string from problem tags, and returns a pytorch vector of floats length n, where a[i] is 1 iff the ith most frequent problem tag is in the list\n",
    "# also make a function that takes a rating and computes its zscore when the mean rating is 1500 and the standard deviation is 300\n",
    "# make an inverse of that function as well\n",
    "from transformers import BertTokenizer\n",
    "def problem_tags_to_vector(tags_string, most_frequent_tags, n):\n",
    "  \"\"\"\n",
    "  Converts a string of problem tags to a PyTorch vector of length n.\n",
    "\n",
    "  Args:\n",
    "    tags_string: A string of problem tags separated by commas.\n",
    "    most_frequent_tags: A set of the n most frequent problem tags.\n",
    "    n: The length of the vector.\n",
    "\n",
    "  Returns:\n",
    "    A PyTorch vector of floats, where a[i] is 1 if the ith most frequent\n",
    "    problem tag is present in the tags_string, and 0 otherwise.\n",
    "  \"\"\"\n",
    "  if not isinstance(tags_string, str):\n",
    "    return torch.zeros(n)\n",
    "  tags = set(tags_string.split(','))\n",
    "  vector = [1.0 if tag in tags else 0.0 for tag in most_frequent_tags]\n",
    "  return torch.tensor(vector, dtype=torch.float32)\n",
    "\n",
    "def rating_to_zscore(rating):\n",
    "  \"\"\"Computes the z-score of a rating.\"\"\"\n",
    "  mean_rating = 1500\n",
    "  std_rating = 300\n",
    "  return (rating - mean_rating) / std_rating\n",
    "\n",
    "def zscore_to_rating(zscore):\n",
    "  \"\"\"Computes the rating from a z-score.\"\"\"\n",
    "  mean_rating = 1500\n",
    "  std_rating = 300\n",
    "  return (zscore * std_rating) + mean_rating\n",
    "\n",
    "MAXLEN = 512\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def tokenize_text(text):\n",
    "  return tokenizer(text, padding='max_length', truncation=True, max_length=MAXLEN)\n",
    "\n",
    "\n",
    "#TODO\n",
    "#MOVE THIS TO A MORE SENSIBLE AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:06:01.185868Z",
     "iopub.status.busy": "2024-11-15T23:06:01.185627Z",
     "iopub.status.idle": "2024-11-15T23:06:02.322412Z",
     "shell.execute_reply": "2024-11-15T23:06:02.321653Z"
    },
    "id": "JW0rR85y-6lC"
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.init as init\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('prajjwal1/bert-small')\n",
    "        self.rating_classifier = nn.Linear(768, 1)  # For regression or binary classification\n",
    "        self.tag_classifier = nn.Linear(768, n)  # Multi-label classification\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        rating_pred = self.rating_classifier(pooled_output)\n",
    "        tag_pred = self.tag_classifier(pooled_output)\n",
    "        return rating_pred, tag_pred\n",
    "\n",
    "class TagModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TagModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('prajjwal1/bert-small')\n",
    "        self.dropout = nn.Dropout(0.4)  # Experiment with dropout rate (e.g., 0.1-0.5)\n",
    "        self.tag_classifier = nn.Sequential(\n",
    "            nn.Linear(512, n),  # Your original linear layer\n",
    "            nn.LayerNorm(n)   # Layer Normalization layer\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)  # Apply dropout\n",
    "        tag_pred = self.tag_classifier(pooled_output)\n",
    "        return tag_pred\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, ratings, tags, device):\n",
    "        self.input_ids = input_ids.to(device)\n",
    "        self.attention_mask = attention_mask.to(device)\n",
    "        self.ratings = ratings.to(device)\n",
    "        self.tags = tags.to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attention_mask[idx], self.ratings[idx], self.tags[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:06:02.324921Z",
     "iopub.status.busy": "2024-11-15T23:06:02.324541Z",
     "iopub.status.idle": "2024-11-15T23:07:57.666241Z",
     "shell.execute_reply": "2024-11-15T23:07:57.665617Z"
    },
    "id": "S0ta2ylDBlP4"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "texts = training_data['problem_statement'].tolist()\n",
    "encodings = tokenizer(texts, truncation=True, padding=True, max_length=MAXLEN)\n",
    "\n",
    "tags = training_data['problem_tags'].tolist()\n",
    "tags = [problem_tags_to_vector(tag, most_frequent_tags, n) for tag in tags]\n",
    "\n",
    "ratings = training_data['rating'].tolist()\n",
    "ratings = [rating_to_zscore(rating) for rating in ratings]\n",
    "\n",
    "input_ids = torch.tensor(encodings['input_ids'])\n",
    "attention_mask = torch.tensor(encodings['attention_mask'])\n",
    "ratings = torch.tensor(ratings, dtype=torch.float32)\n",
    "\n",
    "tags = torch.stack(tags)\n",
    "\n",
    "#validation stuff\n",
    "val_texts = validation_data['problem_statement'].tolist()\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=MAXLEN)\n",
    "\n",
    "val_tags = validation_data['problem_tags'].tolist()\n",
    "val_tags = [problem_tags_to_vector(tag, most_frequent_tags, n) for tag in val_tags]\n",
    "\n",
    "val_ratings = validation_data['rating'].tolist()\n",
    "val_ratings = [rating_to_zscore(rating) for rating in val_ratings]\n",
    "\n",
    "val_input_ids = torch.tensor(val_encodings['input_ids'])\n",
    "val_attention_mask = torch.tensor(val_encodings['attention_mask'])\n",
    "val_ratings = torch.tensor(val_ratings, dtype=torch.float32)\n",
    "\n",
    "val_tags = torch.stack(val_tags)\n",
    "\n",
    "\n",
    "bsz = 32\n",
    "val_dataset = CustomDataset(val_input_ids, val_attention_mask, val_ratings, val_tags, device)\n",
    "val_loader = DataLoader(val_dataset, batch_size=bsz, shuffle=True)\n",
    "dataset = CustomDataset(input_ids, attention_mask, ratings, tags, device)\n",
    "loader = DataLoader(dataset, batch_size=bsz, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:07:57.669690Z",
     "iopub.status.busy": "2024-11-15T23:07:57.669474Z",
     "iopub.status.idle": "2024-11-15T23:07:57.674790Z",
     "shell.execute_reply": "2024-11-15T23:07:57.674363Z"
    },
    "id": "9HiTpnlIQlPU"
   },
   "outputs": [],
   "source": [
    "# prompt: write a function that runs the model on the validation data set, and determines its accuracy on each specific tag. Returns a vector length n with the % accuracy for each tag. The model uses a threshold of 0.5 for classification. remember to apply sigmoid to map the output layer to [0,1]\n",
    "\n",
    "def evaluate_tag_accuracy(model, val_loader, device, n):\n",
    "  \"\"\"\n",
    "  Evaluates the model's accuracy on the validation dataset for each tag.\n",
    "\n",
    "  Args:\n",
    "    model: The trained model.\n",
    "    val_loader: The DataLoader for the validation dataset.\n",
    "    device: The device to run the model on (e.g., 'cuda' or 'cpu').\n",
    "    n: The number of tags.\n",
    "\n",
    "  Returns:\n",
    "    A list of floats, representing the accuracy for each tag.\n",
    "  \"\"\"\n",
    "\n",
    "  model.eval()  # Set the model to evaluation mode\n",
    "  tag_correct_counts = [0] * n\n",
    "  tag_total_counts = [0] * n\n",
    "  avg_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "      input_ids, attention_mask, _, true_tags = batch\n",
    "      input_ids = input_ids.to(device)\n",
    "      attention_mask = attention_mask.to(device)\n",
    "      true_tags = true_tags.to(device)\n",
    "\n",
    "\n",
    "      tag_pred = model(input_ids, attention_mask)\n",
    "      loss = nn.BCEWithLogitsLoss()(tag_pred, true_tags)\n",
    "      avg_loss += loss.item()\n",
    "      tag_pred = torch.sigmoid(tag_pred)  # Apply sigmoid to get probabilities in [0,1]\n",
    "\n",
    "      predicted_tags = (tag_pred > 0.5).float()\n",
    "\n",
    "      for i in range(n):\n",
    "        tag_correct_counts[i] += (predicted_tags[:, i] == true_tags[:, i]).sum().item()\n",
    "        tag_total_counts[i] += true_tags.shape[0]\n",
    "  avg_loss /= len(val_loader)\n",
    "\n",
    "  tag_accuracies = []\n",
    "  for i in range(n):\n",
    "    if tag_total_counts[i] > 0:\n",
    "      tag_accuracies.append(tag_correct_counts[i] / tag_total_counts[i] * 100)\n",
    "    else:\n",
    "      tag_accuracies.append(0.0)\n",
    "\n",
    "  return (avg_loss,tag_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T23:07:57.677666Z",
     "iopub.status.busy": "2024-11-15T23:07:57.677470Z",
     "iopub.status.idle": "2024-11-15T23:32:41.398608Z",
     "shell.execute_reply": "2024-11-15T23:32:41.397929Z"
    },
    "id": "I93aQhCEE5Ph",
    "outputId": "89539d20-d644-4254-977b-7f4cec6b4a2b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "total_losses = []\n",
    "val_losses = []\n",
    "val_acc = []\n",
    "\n",
    "model = TagModel()\n",
    "model.apply(init_weights)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "model.train()\n",
    "\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    loop = tqdm(loader, leave=True) # wrap the dataloader with tqdm\n",
    "    for batch_idx, batch in enumerate(loop):\n",
    "        input_ids, attention_mask, rating_labels, tag_labels = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        tag_pred = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()(tag_pred, tag_labels)\n",
    "\n",
    "        total_losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loop.set_description(f\"Epoch [{epoch + 1}/{EPOCHS}]\")\n",
    "        loop.set_postfix(tag_loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} completed.\")\n",
    "    model.eval()\n",
    "    avg_loss, tag_accuracies = evaluate_tag_accuracy(model, val_loader, device, n)\n",
    "    val_losses.append(avg_loss)\n",
    "    val_acc.append(tag_accuracies)\n",
    "    print(f\"Validation Loss: {avg_loss}\")\n",
    "    print(f\"Tag Accuracies: {tag_accuracies}\")\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:32:41.400733Z",
     "iopub.status.busy": "2024-11-15T23:32:41.400574Z",
     "iopub.status.idle": "2024-11-15T23:32:41.750898Z",
     "shell.execute_reply": "2024-11-15T23:32:41.750455Z"
    },
    "id": "MiqD2Dw68Qyt"
   },
   "outputs": [],
   "source": [
    "# prompt: make 3 charts, one the training loss over time, one the validation loss for each epoch and another with the accuracy rates of each category over each epoch label the categories by their true names found in index_to_tag\n",
    "\n",
    "# Plot training loss over time\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(total_losses)\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.show()\n",
    "\n",
    "# Plot validation loss for each epoch\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss Over Time')\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy rates of each category over epochs\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(n):\n",
    "  accuracies = [epoch_accuracies[i] for epoch_accuracies in val_acc]\n",
    "  plt.plot(accuracies, label=index_to_tag[i])\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy of Each Category Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
